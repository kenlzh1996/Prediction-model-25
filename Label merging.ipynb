{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import re\n",
    "import os\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from numpy.random import MT19937\n",
    "from numpy.random import RandomState, SeedSequence\n",
    "import pandas as pd\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "from pdb import set_trace\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path\n",
    "raw_data_path = '/home/ec2-user/Feb2025/labels/'\n",
    "output_path = '/home/ec2-user/Feb2025/labels/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Marker proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3365, 1)\n"
     ]
    }
   ],
   "source": [
    "# Open the marker protein localization data\n",
    "LFP = 'markers.txt'\n",
    "LD_marker = pd.read_csv(filepath_or_buffer=raw_data_path+LFP,sep='\\t')\n",
    "\n",
    "# Data set wrangling\n",
    "LD_marker.index = LD_marker.loc[:,'Protein']\n",
    "LD_marker = LD_marker.loc[:,LD_marker.columns!='Protein']\n",
    "\n",
    "# Remove unclassified class\n",
    "NotUnclassInd = LD_marker.loc[:,'Localization'] != 'Unclassified'\n",
    "LD_marker = LD_marker.loc[NotUnclassInd,:]\n",
    "print(LD_marker.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MCF7 breast carcinoma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LD MCF7 total labels\n",
      "(9445, 1)\n",
      "LD MCF7 labels after removing existing labels in markers.txt\n",
      "(6130, 1)\n"
     ]
    }
   ],
   "source": [
    "# Open the MCF7 localization data\n",
    "LFP = 'SubCellBarcode.MCF7.txt'\n",
    "LD_mcf7 = pd.read_csv(filepath_or_buffer=raw_data_path+LFP,sep='\\t')\n",
    "\n",
    "# Data set wrangling\n",
    "LD_mcf7.index = LD_mcf7.loc[:,'Protein']\n",
    "LD_mcf7 = LD_mcf7.loc[:,LD_mcf7.columns!='Protein']\n",
    "\n",
    "# Remove unclassified class\n",
    "NotUnclassInd = LD_mcf7.loc[:,'Localization'] != 'Unclassified'\n",
    "LD_mcf7 = LD_mcf7.loc[NotUnclassInd,:]\n",
    "print(\"LD MCF7 total labels\")\n",
    "print(LD_mcf7.shape)\n",
    "\n",
    "# Remove index that already exists in marker LD\n",
    "LD_mcf7 = LD_mcf7.loc[~LD_mcf7.index.isin(LD_marker.index),:]\n",
    "print(\"LD MCF7 labels after removing existing labels in markers.txt\")\n",
    "print(LD_mcf7.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H322 lung carcinoma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LD H322 total labels\n",
      "(9569, 1)\n",
      "LD H322 labels after removing existing labels in markers.txt\n",
      "(6241, 1)\n"
     ]
    }
   ],
   "source": [
    "# Open the H322 localization data\n",
    "LFP = 'SubCellBarcode.H322.txt'\n",
    "LD_h322 = pd.read_csv(filepath_or_buffer=raw_data_path+LFP,sep='\\t')\n",
    "\n",
    "# Data set wrangling\n",
    "LD_h322.index = LD_h322.loc[:,'Protein']\n",
    "LD_h322 = LD_h322.loc[:,LD_h322.columns!='Protein']\n",
    "\n",
    "# Remove unclassified class\n",
    "NotUnclassInd = LD_h322.loc[:,'Localization'] != 'Unclassified'\n",
    "LD_h322 = LD_h322.loc[NotUnclassInd,:]\n",
    "print(\"LD H322 total labels\")\n",
    "print(LD_h322.shape)\n",
    "\n",
    "# Remove index that already exists in marker LD\n",
    "LD_h322 = LD_h322.loc[~LD_h322.index.isin(LD_marker.index),:]\n",
    "print(\"LD H322 labels after removing existing labels in markers.txt\")\n",
    "print(LD_h322.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### U251 brain glioma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LD U251 total labels\n",
      "(9087, 1)\n",
      "LD U251 labels after removing existing labels in markers.txt\n",
      "(5774, 1)\n"
     ]
    }
   ],
   "source": [
    "# Open the U251 localization data\n",
    "LFP = 'SubCellBarcode.U251.txt'\n",
    "LD_u251 = pd.read_csv(filepath_or_buffer=raw_data_path+LFP,sep='\\t')\n",
    "\n",
    "# Data set wrangling\n",
    "LD_u251.index = LD_u251.loc[:,'Protein']\n",
    "LD_u251 = LD_u251.loc[:,LD_u251.columns!='Protein']\n",
    "\n",
    "# Remove unclassified class\n",
    "NotUnclassInd = LD_u251.loc[:,'Localization'] != 'Unclassified'\n",
    "LD_u251 = LD_u251.loc[NotUnclassInd,:]\n",
    "print(\"LD U251 total labels\")\n",
    "print(LD_u251.shape)\n",
    "\n",
    "# Remove index that already exists in marker LD\n",
    "LD_u251 = LD_u251.loc[~LD_u251.index.isin(LD_marker.index),:]\n",
    "print(\"LD U251 labels after removing existing labels in markers.txt\")\n",
    "print(LD_u251.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge for MCF7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9495, 1)\n"
     ]
    }
   ],
   "source": [
    "# Merge all the LD_mcf7 with LD_marker, and save as LD_mcf7_all\n",
    "LD_mcf7_all = pd.concat([LD_marker, LD_mcf7], axis=0)\n",
    "print(LD_mcf7_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Localization\n",
      "Cytosol         3692\n",
      "Nucleus         2671\n",
      "Secretory       2487\n",
      "Mitochondria     645\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# in LD_all, change the localization \"Nuclear\" to \"Nucleus\"\n",
    "LD_mcf7_all.loc[LD_mcf7_all.loc[:,'Localization'] == 'Nuclear','Localization'] = 'Nucleus'\n",
    "LD_mcf7_all_count = LD_mcf7_all.loc[:,'Localization'].value_counts()\n",
    "print(LD_mcf7_all_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LD_mcf7_all.to_csv(output_path+'markers_mcf7_all.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge for H322"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9606, 1)\n"
     ]
    }
   ],
   "source": [
    "# Merge all the LD_h322 with LD_marker, and save as LD_h322_all\n",
    "LD_h322_all = pd.concat([LD_marker, LD_h322], axis=0)\n",
    "print(LD_h322_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Localization\n",
      "Cytosol         3925\n",
      "Nucleus         2524\n",
      "Secretory       2488\n",
      "Mitochondria     669\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# in LD_all, change the localization \"Nuclear\" to \"Nucleus\"\n",
    "LD_h322_all.loc[LD_h322_all.loc[:,'Localization'] == 'Nuclear','Localization'] = 'Nucleus'\n",
    "LD_h322_all_count = LD_h322_all.loc[:,'Localization'].value_counts()\n",
    "print(LD_h322_all_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LD_h322_all.to_csv(output_path+'markers_h322_all.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge for U251"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9139, 1)\n"
     ]
    }
   ],
   "source": [
    "# Merge all the LD_u251 with LD_marker, and save as LD_u251_all\n",
    "LD_u251_all = pd.concat([LD_marker, LD_u251], axis=0)\n",
    "print(LD_u251_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Localization\n",
      "Cytosol         3511\n",
      "Nucleus         2701\n",
      "Secretory       2343\n",
      "Mitochondria     584\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# in LD_all, change the localization \"Nuclear\" to \"Nucleus\"\n",
    "LD_u251_all.loc[LD_u251_all.loc[:,'Localization'] == 'Nuclear','Localization'] = 'Nucleus'\n",
    "LD_u251_all_count = LD_u251_all.loc[:,'Localization'].value_counts()\n",
    "print(LD_u251_all_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LD_u251_all.to_csv(output_path+'markers_u251_all.txt', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
